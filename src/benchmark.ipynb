{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib as imp\n",
    "import argparse\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "import n2v\n",
    "from gensim.models import Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_args():\n",
    "    '''\n",
    "    Parses the node2vec arguments.\n",
    "    '''\n",
    "    parser = argparse.ArgumentParser(description=\"Run node2vec.\")\n",
    "\n",
    "    parser.add_argument('--input', nargs='?', default='graph/karate.edgelist',\n",
    "                        help='Input graph path')\n",
    "\n",
    "    parser.add_argument('--output', nargs='?', default='emb/karate.emb',\n",
    "                        help='Embeddings path')\n",
    "\n",
    "    parser.add_argument('--dimensions', type=int, default=128,\n",
    "                        help='Number of dimensions. Default is 128.')\n",
    "\n",
    "    parser.add_argument('--walk-length', type=int, default=80,\n",
    "                        help='Length of walk per source. Default is 80.')\n",
    "\n",
    "    parser.add_argument('--num-walks', type=int, default=10,\n",
    "                        help='Number of walks per source. Default is 10.')\n",
    "\n",
    "    parser.add_argument('--window-size', type=int, default=10,\n",
    "                        help='Context size for optimization. Default is 10.')\n",
    "\n",
    "    parser.add_argument('--iter', default=1, type=int,\n",
    "                      help='Number of epochs in SGD')\n",
    "\n",
    "    parser.add_argument('--workers', type=int, default=8,\n",
    "                        help='Number of parallel workers. Default is 8.')\n",
    "\n",
    "    parser.add_argument('--p', type=float, default=1,\n",
    "                        help='Return hyperparameter. Default is 1.')\n",
    "\n",
    "    parser.add_argument('--q', type=float, default=1,\n",
    "                        help='Inout hyperparameter. Default is 1.')\n",
    "\n",
    "    parser.add_argument('--weighted', dest='weighted', action='store_true',\n",
    "                        help='Boolean specifying (un)weighted. Default is unweighted.')\n",
    "    parser.add_argument('--unweighted', dest='unweighted', action='store_false')\n",
    "    parser.set_defaults(weighted=False)\n",
    "\n",
    "    parser.add_argument('--directed', dest='directed', action='store_true',\n",
    "                        help='Graph is (un)directed. Default is undirected.')\n",
    "    parser.add_argument('--undirected', dest='undirected', action='store_false')\n",
    "    parser.set_defaults(directed=False)\n",
    "\n",
    "    return parser.parse_args()\n",
    "\n",
    "def read_graph(input, is_weighted, is_directed, nodetype=int, is_using_adjlist=False):\n",
    "    '''\n",
    "    Reads the input network in networkx.\n",
    "    '''\n",
    "    if is_using_adjlist:\n",
    "        G = nx.read_adjlist(input, comments='#', delimiter=\" \", nodetype=nodetype)\n",
    "        for edge in G.edges():\n",
    "            G[edge[0]][edge[1]]['weight'] = 1\n",
    "    else:\n",
    "        if is_weighted:\n",
    "            G = nx.read_edgelist(input, nodetype=nodetype, data=(('weight',float),), create_using=nx.DiGraph())\n",
    "        else:\n",
    "            G = nx.read_edgelist(input, nodetype=nodetype, create_using=nx.DiGraph())\n",
    "            for edge in G.edges():\n",
    "                G[edge[0]][edge[1]]['weight'] = 1\n",
    "\n",
    "    if not is_directed:\n",
    "        G = G.to_undirected()\n",
    "    return G\n",
    "\n",
    "def learn_embeddings(walks, dimensions, window_size, workers, iter, output):\n",
    "    '''\n",
    "    Learn embeddings by optimizing the Skipgram objective using SGD.\n",
    "    '''\n",
    "    walks = [list(map(str, walk)) for walk in walks]\n",
    "    model = Word2Vec(walks, size=dimensions, window=window_size, min_count=0, sg=1, workers=workers, iter=iter)\n",
    "    model.wv.save_word2vec_format(output)\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simple demo\n",
    "n2v = imp.reload(n2v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Walk iteration:\n",
      "1 / 10\n",
      "2 / 10\n",
      "3 / 10\n",
      "4 / 10\n",
      "5 / 10\n",
      "6 / 10\n",
      "7 / 10\n",
      "8 / 10\n",
      "9 / 10\n",
      "10 / 10\n"
     ]
    }
   ],
   "source": [
    "# build\n",
    "FN_EDGELIST = \"../data/karate.edgelist\"\n",
    "FN_EMBEDDINGS = \"../output/karate.emb\"\n",
    "nx_G = read_graph(input=FN_EDGELIST, is_weighted=False, is_directed=False)\n",
    "G = n2v.Graph(nx_G, is_directed=False, is_weighted=False, p=1, q=1)\n",
    "G.preprocess_transition_probs()\n",
    "walks = G.simulate_walks(num_walks=10, walk_length=80)\n",
    "learn_embeddings(walks, dimensions=128, window_size=10, workers=8, iter=1, output=FN_EMBEDDINGS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "most_similar: [('4', 0.9985132217407227), ('8', 0.9975525140762329), ('13', 0.9954157471656799), ('2', 0.9953797459602356), ('14', 0.9941872358322144), ('20', 0.9923473596572876), ('18', 0.9899183511734009), ('17', 0.9883556962013245), ('7', 0.9867613315582275), ('12', 0.984230637550354)]\n"
     ]
    }
   ],
   "source": [
    "# search\n",
    "from gensim.models import KeyedVectors\n",
    "model = KeyedVectors.load_word2vec_format(FN_EMBEDDINGS, binary=False)\n",
    "print(\"most_similar: {}\".format(model.most_similar(\"1\"), topn=10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get hands dirty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "FN_USER_ITEM_LABEL = \"../data/user_item_label.txt\"\n",
    "FN_ITEM_TITLE = \"../data/item_title.index\"\n",
    "FN_UI_ADJ = \"../data/user_items.adjlist\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load item titles\n",
    "def load_item_titles(fn):\n",
    "    item_title_dict = {}\n",
    "    idx = 1\n",
    "    with open(fn) as fd:\n",
    "        for line in fd:\n",
    "            line = line.rstrip()\n",
    "            item_title_dict[\"I{}\".format(idx)] = line\n",
    "            idx += 1\n",
    "    return item_title_dict\n",
    "item_title_dict = load_item_titles(FN_ITEM_TITLE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I1: 动画片 | 海绵宝宝：剧情幽默而充满想象力\n"
     ]
    }
   ],
   "source": [
    "print(\"I1: {}\".format(item_title_dict[\"I1\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tmp_inspect(fn):\n",
    "    valid_users = set()\n",
    "    valid_items = set()\n",
    "    all_users = set()\n",
    "    all_items = set()\n",
    "    with open(fn) as fd:\n",
    "        for line in fd:\n",
    "            arr = line.rstrip().split(\",\")\n",
    "            if len(arr) != 3:\n",
    "                continue\n",
    "            all_users.add(arr[0])\n",
    "            all_items.add(arr[1])\n",
    "            if arr[2] == \"1\":\n",
    "                valid_users.add(\"U{}\".format(arr[0]))\n",
    "                valid_items.add(\"I{}\".format(arr[1]))\n",
    "    return valid_users, all_users, valid_items, all_items\n",
    "valid_users, all_users, valid_items, all_items = tmp_inspect(FN_USER_ITEM_LABEL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83719 100000 299 571\n"
     ]
    }
   ],
   "source": [
    "print(len(valid_users), len(all_users), len(valid_items), len(all_items))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(sorted(list(valid_items), key=lambda x: int(x[1:]), reverse=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "def generate_adjlist_file(fn_in, fn_out):\n",
    "    user_items_dict = defaultdict(set)\n",
    "    with open(fn_in) as fd:\n",
    "        for line in fd:\n",
    "            arr = line.rstrip().split(\",\")\n",
    "            if len(arr) != 3:\n",
    "                continue\n",
    "            if arr[2] == \"1\":\n",
    "                user_items_dict[\"U{}\".format(arr[0])].add(\"I{}\".format(arr[1]))\n",
    "    with open(fn_out, \"w\") as fd:\n",
    "        for user, item_set in user_items_dict.items():\n",
    "            fd.write(\"{} {}\\n\".format(user, \" \".join(item_set)))\n",
    "    return user_items_dict\n",
    "user_items_dict = generate_adjlist_file(FN_USER_ITEM_LABEL, FN_UI_ADJ)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'I147', 'I12', 'I46', 'I146', 'I91', 'I44', 'I41'}\n"
     ]
    }
   ],
   "source": [
    "print(user_items_dict[\"U2\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Read graph ..\n",
      "Init graph ..\n"
     ]
    }
   ],
   "source": [
    "# build\n",
    "n2v = imp.reload(n2v)\n",
    "print(\"Read graph ..\")\n",
    "nx_G = read_graph(FN_UI_ADJ, is_weighted=False, is_directed=False, nodetype=str, is_using_adjlist=True)\n",
    "print(\"Init graph ..\")\n",
    "G = n2v.Graph(nx_G, is_directed=False, is_weighted=False, p=1, q=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Preprocessing probs ..\")\n",
    "G.preprocess_transition_probs()\n",
    "print(\"Generate walks ..\")\n",
    "walks = G.simulate_walks(num_walks=10, walk_length=80)\n",
    "print(\"Generate Embeddings ..\")\n",
    "learn_embeddings(walks, dimensions=128, window_size=10, workers=8, iter=1, output=FN_EMBEDDINGS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# search\n",
    "from gensim.models import KeyedVectors\n",
    "model = KeyedVectors.load_word2vec_format(FN_EMBEDDINGS, binary=False)\n",
    "print(\"most_similar: {}\".format(model.most_similar(\"1\"), topn=10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test\n",
    "nx_G.degree(\"I24\")\n",
    "nx_G.is_directed()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
